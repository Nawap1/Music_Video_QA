{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10576580,"sourceType":"datasetVersion","datasetId":6544541}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt","metadata":{"_uuid":"87d75181-fdf8-411b-91e4-bc7eaac6a721","_cell_guid":"7519b00d-e733-4ee5-829b-36d9c5fffb3d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:36:28.580644Z","iopub.execute_input":"2025-01-25T17:36:28.580959Z","iopub.status.idle":"2025-01-25T17:36:28.584908Z","shell.execute_reply.started":"2025-01-25T17:36:28.580933Z","shell.execute_reply":"2025-01-25T17:36:28.584001Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/videoframedata/new_frame_data.csv')","metadata":{"_uuid":"6c1929ff-9dfb-4b8f-96e8-4fc5169aa518","_cell_guid":"fdc5fdd1-2492-40ee-bbdf-a8719278daf7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:36:28.589424Z","iopub.execute_input":"2025-01-25T17:36:28.589670Z","iopub.status.idle":"2025-01-25T17:36:29.025747Z","shell.execute_reply.started":"2025-01-25T17:36:28.589616Z","shell.execute_reply":"2025-01-25T17:36:29.025043Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## FUCK MEE","metadata":{"_uuid":"1ac19998-92e1-4c38-91ea-f6864fc2a2a2","_cell_guid":"b626f5b6-c536-4a15-b1c9-d47385e1356a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"%%capture\n!pip install -q unsloth\n# Also get the latest nightly Unsloth!\n!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"_uuid":"ac4f763e-3bdc-4955-9ed4-5d59800c5828","_cell_guid":"957887ca-fd7c-4931-ac50-be2dcb2ebf94","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:36:29.026902Z","iopub.execute_input":"2025-01-25T17:36:29.027177Z","iopub.status.idle":"2025-01-25T17:36:42.041241Z","shell.execute_reply.started":"2025-01-25T17:36:29.027154Z","shell.execute_reply":"2025-01-25T17:36:42.040148Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastVisionModel \nimport torch","metadata":{"_uuid":"e849e6a1-a765-479e-be74-1e442f6deb9b","_cell_guid":"934054a5-f5e7-4d93-8480-332f62cacf81","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:36:42.043254Z","iopub.execute_input":"2025-01-25T17:36:42.043483Z","iopub.status.idle":"2025-01-25T17:37:09.366179Z","shell.execute_reply.started":"2025-01-25T17:36:42.043459Z","shell.execute_reply":"2025-01-25T17:37:09.365525Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, tokenizer = FastVisionModel.from_pretrained(\n    \"unsloth/Qwen2-VL-2B-Instruct\",\n    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n)","metadata":{"_uuid":"2e0cfb76-298a-4a0b-9b89-3b6932592d17","_cell_guid":"6bba8ab1-af40-4ad7-a282-ba6594352d48","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:37:09.367502Z","iopub.execute_input":"2025-01-25T17:37:09.367818Z","iopub.status.idle":"2025-01-25T17:37:25.661300Z","shell.execute_reply.started":"2025-01-25T17:37:09.367787Z","shell.execute_reply":"2025-01-25T17:37:25.660670Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = FastVisionModel.get_peft_model(\n    model,\n    finetune_vision_layers     = True, \n    finetune_language_layers   = True, \n    finetune_attention_modules = True, \n    finetune_mlp_modules       = True, \n\n    r = 16,         \n    lora_alpha = 16,  \n    lora_dropout = 0,\n    bias = \"none\",\n    random_state = 3407,\n    use_rslora = False,  \n    loftq_config = None, \n    \n)","metadata":{"_uuid":"2eb148a7-af51-451c-9b3b-8a5b11d59160","_cell_guid":"c7acb90a-55f6-47fa-ba0f-992d65c72ef7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:37:25.662067Z","iopub.execute_input":"2025-01-25T17:37:25.662269Z","iopub.status.idle":"2025-01-25T17:37:30.788677Z","shell.execute_reply.started":"2025-01-25T17:37:25.662249Z","shell.execute_reply":"2025-01-25T17:37:30.787788Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\noutput_path = \"/kaggle/working/dataset.json\"\n\n# Convert the dataset to JSONL format\nwith open(output_path, \"w\") as f:\n    for _, row in df.iterrows():\n        json_data = {\n            \"image_path\": row[\"frame_path\"], \n            \"question\": row[\"question\"],     \n            \"answer\": row[\"refined_answer\"]  \n        }\n        f.write(json.dumps(json_data) + \"\\n\")\n\nprint(f\"JSONL file saved to: {output_path}\")","metadata":{"_uuid":"b9ab3d33-0bec-4bd0-a095-505a1c31e2bf","_cell_guid":"9acefd14-13de-4af0-9d21-dfe3be0d7750","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:37:30.789580Z","iopub.execute_input":"2025-01-25T17:37:30.789928Z","iopub.status.idle":"2025-01-25T17:37:33.891328Z","shell.execute_reply.started":"2025-01-25T17:37:30.789894Z","shell.execute_reply":"2025-01-25T17:37:33.890559Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = []\nwith open(output_path, \"r\") as f:\n    for line in f:\n        data.append(json.loads(line))","metadata":{"_uuid":"4a9b6a08-edae-4e18-81b4-170107d6feab","_cell_guid":"223a8768-7a09-4df8-b50f-f7769bcf224a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:37:33.892125Z","iopub.execute_input":"2025-01-25T17:37:33.892423Z","iopub.status.idle":"2025-01-25T17:37:35.361673Z","shell.execute_reply.started":"2025-01-25T17:37:33.892389Z","shell.execute_reply":"2025-01-25T17:37:35.360728Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = data[1][\"image_path\"]\nquestion = data[1][\"question\"]\nanswer = data[1][\"answer\"]\n\nprint(f\"Image Path: {image_path}\")\nprint(f\"Question: {question}\")\nprint(f\"Answer: {answer}\")","metadata":{"_uuid":"be4688f7-ed9b-4c29-825b-0b80b05113d4","_cell_guid":"6168c262-3ce9-4d7b-a5ff-47716c21b5b6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:37:35.364422Z","iopub.execute_input":"2025-01-25T17:37:35.364680Z","iopub.status.idle":"2025-01-25T17:37:35.369960Z","shell.execute_reply.started":"2025-01-25T17:37:35.364650Z","shell.execute_reply":"2025-01-25T17:37:35.369136Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\nfrom PIL import Image\n\n# Instruction for the dataset\ninstruction = \"Answer the question based on the content of this image.\"\n\n# Function to convert a single sample into a conversation format\ndef convert_to_conversation(sample):\n    try:\n        # Load the image using PIL\n        image = Image.open(sample[\"image_path\"])\n        expected_size = (224, 224)\n        # Resize the image\n        image = image.resize(expected_size)\n        \n        conversation = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": instruction},\n                    {\"type\": \"image\", \"image\": image}, # Pass the resized image\n                    {\"type\": \"text\", \"text\": sample[\"question\"]}\n                ]\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": sample[\"answer\"]}\n                ]\n            },\n        ]\n        return {\"messages\": conversation}\n    except Exception as e:\n        print(f\"Error processing image {sample['image_path']}: {e}\")\n        return None # Skip the image if there's an error","metadata":{"_uuid":"a40506ab-1823-4337-a4bc-6c3a892390d5","_cell_guid":"bc6a4f59-d116-4a67-9e97-1c240eca66de","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:37:35.371158Z","iopub.execute_input":"2025-01-25T17:37:35.371383Z","iopub.status.idle":"2025-01-25T17:37:35.381823Z","shell.execute_reply.started":"2025-01-25T17:37:35.371365Z","shell.execute_reply":"2025-01-25T17:37:35.380862Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"converted_dataset = [convert_to_conversation(sample) for sample in tqdm(data, desc=\"Processing Samples\")]\nconverted_dataset = [sample for sample in converted_dataset if sample is not None]","metadata":{"_uuid":"e99d1c53-01e2-46a2-bbb7-473067cfe496","_cell_guid":"b7af16be-5aff-4b4a-90a9-8be10174c00d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:37:35.382689Z","iopub.execute_input":"2025-01-25T17:37:35.382928Z","iopub.status.idle":"2025-01-25T17:59:40.259416Z","shell.execute_reply.started":"2025-01-25T17:37:35.382897Z","shell.execute_reply":"2025-01-25T17:59:40.258445Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nfrom transformers import TextStreamer\n\nmodel = FastVisionModel.for_inference(model)\n\nimage = converted_dataset[0]['messages'][0]['content'][1]['image']\n\ninstruction = \"Answer the question based on the content of this image.\"\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": image},  \n            {\"type\": \"text\", \"text\": instruction}\n        ]\n    }\n]\n\ninput_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\nprint(input_text)\n\ninputs = tokenizer(\n    image,\n    input_text,\n    add_special_tokens = False,\n    return_tensors = \"pt\",\n).to(\"cuda\")\nprint(inputs)\n\n# Define the text streamer\ntext_streamer = TextStreamer(\n    tokenizer=tokenizer,\n    skip_prompt=True  # Skip showing the input prompt in the output\n)\nprint(text_streamer)\n\n# Generate the output\nwith torch.no_grad():  # Disable gradient computation during inference\n    _ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128,\n                       use_cache=True, temperature=1.5, min_p=0.1)","metadata":{"_uuid":"7e7148f8-1518-457c-97b9-7b78417272c4","_cell_guid":"bbaed084-eab4-4862-a7d9-2e2be5aa421a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T17:59:40.260448Z","iopub.execute_input":"2025-01-25T17:59:40.260812Z","iopub.status.idle":"2025-01-25T18:00:14.341965Z","shell.execute_reply.started":"2025-01-25T17:59:40.260779Z","shell.execute_reply":"2025-01-25T18:00:14.341305Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\n\ndef compute_bleu(eval_preds):\n    predictions, labels = eval_preds\n    # Decode predictions and labels\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Tokenize predictions and labels\n    tokenized_preds = [pred.split() for pred in decoded_preds]\n    tokenized_labels = [[label.split()] for label in decoded_labels]  # Nested for multiple references\n    \n    # Calculate BLEU score\n    bleu_score = corpus_bleu(tokenized_labels, tokenized_preds)\n    return {\"bleu\": bleu_score}","metadata":{"_uuid":"f4d23b75-de28-48ca-ab93-113ccd805ad9","_cell_guid":"81cf7549-cfec-4413-b6a8-184438e904a5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:43:08.364066Z","iopub.execute_input":"2025-01-25T18:43:08.364366Z","iopub.status.idle":"2025-01-25T18:43:08.369360Z","shell.execute_reply.started":"2025-01-25T18:43:08.364344Z","shell.execute_reply":"2025-01-25T18:43:08.368351Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_data, val_data = train_test_split(converted_dataset, test_size=0.2, random_state=42)","metadata":{"_uuid":"23e75fba-bf21-4e5e-b1db-32ba11675d9f","_cell_guid":"8e8bed3a-0132-46ad-b77b-01af025eb750","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:44:07.039909Z","iopub.execute_input":"2025-01-25T18:44:07.040201Z","iopub.status.idle":"2025-01-25T18:44:07.061459Z","shell.execute_reply.started":"2025-01-25T18:44:07.040179Z","shell.execute_reply":"2025-01-25T18:44:07.060694Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import is_bf16_supported\nfrom unsloth.trainer import UnslothVisionDataCollator\nfrom trl import SFTTrainer, SFTConfig\n\nFastVisionModel.for_training(model) # Enable for training!\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    data_collator = UnslothVisionDataCollator(model, tokenizer), # Must use!\n    train_dataset = converted_dataset,\n    args = SFTConfig(\n        per_device_train_batch_size = 4,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        max_steps = 500,\n        # num_train_epochs = 1, # Set this instead of max_steps for full training runs\n        learning_rate = 1e-5,\n        fp16 = not is_bf16_supported(),\n        bf16 = is_bf16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\",  \n\n        # You MUST put the below items for vision finetuning:\n        remove_unused_columns = False,\n        dataset_text_field = \"\",\n        dataset_kwargs = {\"skip_prepare_dataset\": True},\n        dataset_num_proc = 4,\n        max_seq_length = 2048,\n    ),\n)","metadata":{"_uuid":"a91150f4-6caa-4bf5-9feb-7c733d0d6810","_cell_guid":"5dade834-714e-4754-832e-8eed1c0e4073","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:55:52.807388Z","iopub.execute_input":"2025-01-25T18:55:52.807766Z","iopub.status.idle":"2025-01-25T18:55:52.897070Z","shell.execute_reply.started":"2025-01-25T18:55:52.807735Z","shell.execute_reply":"2025-01-25T18:55:52.896177Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"gpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"_uuid":"6764abed-b948-4ec4-a69c-cc84fbd071de","_cell_guid":"545c6acd-dd08-4325-bd60-e6e4ee39eb37","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:55:54.637747Z","iopub.execute_input":"2025-01-25T18:55:54.638052Z","iopub.status.idle":"2025-01-25T18:55:54.643592Z","shell.execute_reply.started":"2025-01-25T18:55:54.638030Z","shell.execute_reply":"2025-01-25T18:55:54.642921Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n3.068 GB of memory reserved.\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"_uuid":"4c8c007a-d815-4e42-ab86-6381896df5e7","_cell_guid":"387456f1-8fd6-4f0e-a555-25df41c5530d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:55:56.406099Z","iopub.execute_input":"2025-01-25T18:55:56.406390Z","iopub.status.idle":"2025-01-25T19:52:44.771587Z","shell.execute_reply.started":"2025-01-25T18:55:56.406369Z","shell.execute_reply":"2025-01-25T19:52:44.770714Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 55,244 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 16 | Total steps = 500\n \"-____-\"     Number of trainable parameters = 28,950,528\nðŸ¦¥ Unsloth needs about 1-3 minutes to load everything - please wait!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 56:33, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.429800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.434800</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.469800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.501700</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.553300</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.489200</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.581700</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.542000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.531200</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.511200</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.425000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.468900</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.549200</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.569700</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.503100</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.532900</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.532000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.591300</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.643000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.545800</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.827200</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.798000</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.728400</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.628900</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.757800</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.783800</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.764800</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.847200</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.759500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.846100</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.848600</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.941900</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.841700</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.927100</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.957500</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.849900</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.964500</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.909100</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.889400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.945400</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.933200</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.860000</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.978000</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.784400</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.867200</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.847500</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.766700</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.875900</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.960500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.932700</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.872400</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.010300</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.907200</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.799600</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.795900</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.748700</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.868300</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.754200</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.883200</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.689700</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.000400</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.847900</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.845600</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.828900</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.796800</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.884900</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.785400</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.868400</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.905900</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.843600</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.845900</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.818400</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.774800</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>1.064900</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.942100</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.783000</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.820600</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.783000</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.974700</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.819500</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.909100</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.883600</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.870900</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.833100</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.838400</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.771000</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.645900</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.781800</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.810100</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.833300</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.901600</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.817200</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.848100</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.751800</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.930700</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.784500</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.823300</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.862900</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.870900</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.800200</td>\n    </tr>\n    <tr>\n      <td>101</td>\n      <td>0.835900</td>\n    </tr>\n    <tr>\n      <td>102</td>\n      <td>0.830800</td>\n    </tr>\n    <tr>\n      <td>103</td>\n      <td>0.782600</td>\n    </tr>\n    <tr>\n      <td>104</td>\n      <td>0.839800</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.858000</td>\n    </tr>\n    <tr>\n      <td>106</td>\n      <td>0.738900</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>0.950100</td>\n    </tr>\n    <tr>\n      <td>108</td>\n      <td>0.917100</td>\n    </tr>\n    <tr>\n      <td>109</td>\n      <td>0.980500</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.849900</td>\n    </tr>\n    <tr>\n      <td>111</td>\n      <td>0.810000</td>\n    </tr>\n    <tr>\n      <td>112</td>\n      <td>0.897300</td>\n    </tr>\n    <tr>\n      <td>113</td>\n      <td>0.872200</td>\n    </tr>\n    <tr>\n      <td>114</td>\n      <td>0.843300</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.861200</td>\n    </tr>\n    <tr>\n      <td>116</td>\n      <td>0.726500</td>\n    </tr>\n    <tr>\n      <td>117</td>\n      <td>0.859400</td>\n    </tr>\n    <tr>\n      <td>118</td>\n      <td>0.749200</td>\n    </tr>\n    <tr>\n      <td>119</td>\n      <td>0.938000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.745900</td>\n    </tr>\n    <tr>\n      <td>121</td>\n      <td>0.838100</td>\n    </tr>\n    <tr>\n      <td>122</td>\n      <td>0.753600</td>\n    </tr>\n    <tr>\n      <td>123</td>\n      <td>0.876800</td>\n    </tr>\n    <tr>\n      <td>124</td>\n      <td>0.842000</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.845600</td>\n    </tr>\n    <tr>\n      <td>126</td>\n      <td>0.843500</td>\n    </tr>\n    <tr>\n      <td>127</td>\n      <td>0.809800</td>\n    </tr>\n    <tr>\n      <td>128</td>\n      <td>1.029400</td>\n    </tr>\n    <tr>\n      <td>129</td>\n      <td>0.897100</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.935400</td>\n    </tr>\n    <tr>\n      <td>131</td>\n      <td>0.821000</td>\n    </tr>\n    <tr>\n      <td>132</td>\n      <td>0.871800</td>\n    </tr>\n    <tr>\n      <td>133</td>\n      <td>0.865100</td>\n    </tr>\n    <tr>\n      <td>134</td>\n      <td>0.890500</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.759900</td>\n    </tr>\n    <tr>\n      <td>136</td>\n      <td>0.762600</td>\n    </tr>\n    <tr>\n      <td>137</td>\n      <td>0.934100</td>\n    </tr>\n    <tr>\n      <td>138</td>\n      <td>0.758600</td>\n    </tr>\n    <tr>\n      <td>139</td>\n      <td>0.842800</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.870800</td>\n    </tr>\n    <tr>\n      <td>141</td>\n      <td>0.902200</td>\n    </tr>\n    <tr>\n      <td>142</td>\n      <td>0.838500</td>\n    </tr>\n    <tr>\n      <td>143</td>\n      <td>0.766300</td>\n    </tr>\n    <tr>\n      <td>144</td>\n      <td>0.881400</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.793700</td>\n    </tr>\n    <tr>\n      <td>146</td>\n      <td>0.772100</td>\n    </tr>\n    <tr>\n      <td>147</td>\n      <td>0.818700</td>\n    </tr>\n    <tr>\n      <td>148</td>\n      <td>0.735500</td>\n    </tr>\n    <tr>\n      <td>149</td>\n      <td>0.825400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.836600</td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>0.792300</td>\n    </tr>\n    <tr>\n      <td>152</td>\n      <td>0.889400</td>\n    </tr>\n    <tr>\n      <td>153</td>\n      <td>0.918300</td>\n    </tr>\n    <tr>\n      <td>154</td>\n      <td>0.774400</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.906300</td>\n    </tr>\n    <tr>\n      <td>156</td>\n      <td>0.817800</td>\n    </tr>\n    <tr>\n      <td>157</td>\n      <td>0.817300</td>\n    </tr>\n    <tr>\n      <td>158</td>\n      <td>0.883400</td>\n    </tr>\n    <tr>\n      <td>159</td>\n      <td>0.931700</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.815100</td>\n    </tr>\n    <tr>\n      <td>161</td>\n      <td>0.835000</td>\n    </tr>\n    <tr>\n      <td>162</td>\n      <td>0.954400</td>\n    </tr>\n    <tr>\n      <td>163</td>\n      <td>0.827800</td>\n    </tr>\n    <tr>\n      <td>164</td>\n      <td>0.805100</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.871200</td>\n    </tr>\n    <tr>\n      <td>166</td>\n      <td>0.851100</td>\n    </tr>\n    <tr>\n      <td>167</td>\n      <td>0.708800</td>\n    </tr>\n    <tr>\n      <td>168</td>\n      <td>0.819500</td>\n    </tr>\n    <tr>\n      <td>169</td>\n      <td>0.902000</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.955100</td>\n    </tr>\n    <tr>\n      <td>171</td>\n      <td>0.842000</td>\n    </tr>\n    <tr>\n      <td>172</td>\n      <td>0.791900</td>\n    </tr>\n    <tr>\n      <td>173</td>\n      <td>0.835300</td>\n    </tr>\n    <tr>\n      <td>174</td>\n      <td>0.831700</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.849700</td>\n    </tr>\n    <tr>\n      <td>176</td>\n      <td>0.774000</td>\n    </tr>\n    <tr>\n      <td>177</td>\n      <td>0.910400</td>\n    </tr>\n    <tr>\n      <td>178</td>\n      <td>0.822000</td>\n    </tr>\n    <tr>\n      <td>179</td>\n      <td>0.937300</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.767500</td>\n    </tr>\n    <tr>\n      <td>181</td>\n      <td>0.782600</td>\n    </tr>\n    <tr>\n      <td>182</td>\n      <td>0.904300</td>\n    </tr>\n    <tr>\n      <td>183</td>\n      <td>0.780200</td>\n    </tr>\n    <tr>\n      <td>184</td>\n      <td>0.850100</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.852000</td>\n    </tr>\n    <tr>\n      <td>186</td>\n      <td>0.969000</td>\n    </tr>\n    <tr>\n      <td>187</td>\n      <td>0.841100</td>\n    </tr>\n    <tr>\n      <td>188</td>\n      <td>0.921600</td>\n    </tr>\n    <tr>\n      <td>189</td>\n      <td>0.728600</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.817900</td>\n    </tr>\n    <tr>\n      <td>191</td>\n      <td>0.926700</td>\n    </tr>\n    <tr>\n      <td>192</td>\n      <td>0.779900</td>\n    </tr>\n    <tr>\n      <td>193</td>\n      <td>0.820800</td>\n    </tr>\n    <tr>\n      <td>194</td>\n      <td>0.871400</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.854000</td>\n    </tr>\n    <tr>\n      <td>196</td>\n      <td>0.842300</td>\n    </tr>\n    <tr>\n      <td>197</td>\n      <td>0.823700</td>\n    </tr>\n    <tr>\n      <td>198</td>\n      <td>0.779800</td>\n    </tr>\n    <tr>\n      <td>199</td>\n      <td>0.816800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.902500</td>\n    </tr>\n    <tr>\n      <td>201</td>\n      <td>0.841600</td>\n    </tr>\n    <tr>\n      <td>202</td>\n      <td>0.809500</td>\n    </tr>\n    <tr>\n      <td>203</td>\n      <td>0.780500</td>\n    </tr>\n    <tr>\n      <td>204</td>\n      <td>0.853400</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.761000</td>\n    </tr>\n    <tr>\n      <td>206</td>\n      <td>0.749700</td>\n    </tr>\n    <tr>\n      <td>207</td>\n      <td>0.933600</td>\n    </tr>\n    <tr>\n      <td>208</td>\n      <td>0.852100</td>\n    </tr>\n    <tr>\n      <td>209</td>\n      <td>0.894500</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.823300</td>\n    </tr>\n    <tr>\n      <td>211</td>\n      <td>0.885600</td>\n    </tr>\n    <tr>\n      <td>212</td>\n      <td>0.795700</td>\n    </tr>\n    <tr>\n      <td>213</td>\n      <td>0.808100</td>\n    </tr>\n    <tr>\n      <td>214</td>\n      <td>0.929600</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.963300</td>\n    </tr>\n    <tr>\n      <td>216</td>\n      <td>1.000700</td>\n    </tr>\n    <tr>\n      <td>217</td>\n      <td>0.891400</td>\n    </tr>\n    <tr>\n      <td>218</td>\n      <td>0.861600</td>\n    </tr>\n    <tr>\n      <td>219</td>\n      <td>0.816200</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.887700</td>\n    </tr>\n    <tr>\n      <td>221</td>\n      <td>0.750600</td>\n    </tr>\n    <tr>\n      <td>222</td>\n      <td>0.739700</td>\n    </tr>\n    <tr>\n      <td>223</td>\n      <td>0.840500</td>\n    </tr>\n    <tr>\n      <td>224</td>\n      <td>0.913900</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.894000</td>\n    </tr>\n    <tr>\n      <td>226</td>\n      <td>0.869700</td>\n    </tr>\n    <tr>\n      <td>227</td>\n      <td>0.729200</td>\n    </tr>\n    <tr>\n      <td>228</td>\n      <td>0.876700</td>\n    </tr>\n    <tr>\n      <td>229</td>\n      <td>0.900200</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.781100</td>\n    </tr>\n    <tr>\n      <td>231</td>\n      <td>0.872700</td>\n    </tr>\n    <tr>\n      <td>232</td>\n      <td>0.817000</td>\n    </tr>\n    <tr>\n      <td>233</td>\n      <td>0.865900</td>\n    </tr>\n    <tr>\n      <td>234</td>\n      <td>0.796600</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.878500</td>\n    </tr>\n    <tr>\n      <td>236</td>\n      <td>0.793400</td>\n    </tr>\n    <tr>\n      <td>237</td>\n      <td>0.886000</td>\n    </tr>\n    <tr>\n      <td>238</td>\n      <td>0.842600</td>\n    </tr>\n    <tr>\n      <td>239</td>\n      <td>0.819300</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.831900</td>\n    </tr>\n    <tr>\n      <td>241</td>\n      <td>0.914500</td>\n    </tr>\n    <tr>\n      <td>242</td>\n      <td>0.737800</td>\n    </tr>\n    <tr>\n      <td>243</td>\n      <td>0.904600</td>\n    </tr>\n    <tr>\n      <td>244</td>\n      <td>0.883100</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>0.889700</td>\n    </tr>\n    <tr>\n      <td>246</td>\n      <td>0.888400</td>\n    </tr>\n    <tr>\n      <td>247</td>\n      <td>0.713500</td>\n    </tr>\n    <tr>\n      <td>248</td>\n      <td>0.951100</td>\n    </tr>\n    <tr>\n      <td>249</td>\n      <td>0.892600</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.932000</td>\n    </tr>\n    <tr>\n      <td>251</td>\n      <td>0.862000</td>\n    </tr>\n    <tr>\n      <td>252</td>\n      <td>0.819100</td>\n    </tr>\n    <tr>\n      <td>253</td>\n      <td>0.750100</td>\n    </tr>\n    <tr>\n      <td>254</td>\n      <td>0.885600</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>0.873300</td>\n    </tr>\n    <tr>\n      <td>256</td>\n      <td>0.883700</td>\n    </tr>\n    <tr>\n      <td>257</td>\n      <td>0.861600</td>\n    </tr>\n    <tr>\n      <td>258</td>\n      <td>0.806800</td>\n    </tr>\n    <tr>\n      <td>259</td>\n      <td>0.921900</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.893000</td>\n    </tr>\n    <tr>\n      <td>261</td>\n      <td>0.766600</td>\n    </tr>\n    <tr>\n      <td>262</td>\n      <td>0.846600</td>\n    </tr>\n    <tr>\n      <td>263</td>\n      <td>0.813800</td>\n    </tr>\n    <tr>\n      <td>264</td>\n      <td>0.803000</td>\n    </tr>\n    <tr>\n      <td>265</td>\n      <td>0.899000</td>\n    </tr>\n    <tr>\n      <td>266</td>\n      <td>0.928600</td>\n    </tr>\n    <tr>\n      <td>267</td>\n      <td>0.861700</td>\n    </tr>\n    <tr>\n      <td>268</td>\n      <td>0.932600</td>\n    </tr>\n    <tr>\n      <td>269</td>\n      <td>0.773400</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.883000</td>\n    </tr>\n    <tr>\n      <td>271</td>\n      <td>0.829600</td>\n    </tr>\n    <tr>\n      <td>272</td>\n      <td>0.877800</td>\n    </tr>\n    <tr>\n      <td>273</td>\n      <td>0.825800</td>\n    </tr>\n    <tr>\n      <td>274</td>\n      <td>0.759400</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.813700</td>\n    </tr>\n    <tr>\n      <td>276</td>\n      <td>0.884300</td>\n    </tr>\n    <tr>\n      <td>277</td>\n      <td>0.971000</td>\n    </tr>\n    <tr>\n      <td>278</td>\n      <td>0.727700</td>\n    </tr>\n    <tr>\n      <td>279</td>\n      <td>0.838500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.858200</td>\n    </tr>\n    <tr>\n      <td>281</td>\n      <td>0.786700</td>\n    </tr>\n    <tr>\n      <td>282</td>\n      <td>0.831500</td>\n    </tr>\n    <tr>\n      <td>283</td>\n      <td>0.866200</td>\n    </tr>\n    <tr>\n      <td>284</td>\n      <td>0.784200</td>\n    </tr>\n    <tr>\n      <td>285</td>\n      <td>0.889500</td>\n    </tr>\n    <tr>\n      <td>286</td>\n      <td>0.743000</td>\n    </tr>\n    <tr>\n      <td>287</td>\n      <td>0.832100</td>\n    </tr>\n    <tr>\n      <td>288</td>\n      <td>0.822300</td>\n    </tr>\n    <tr>\n      <td>289</td>\n      <td>0.848900</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.983100</td>\n    </tr>\n    <tr>\n      <td>291</td>\n      <td>0.840300</td>\n    </tr>\n    <tr>\n      <td>292</td>\n      <td>0.899700</td>\n    </tr>\n    <tr>\n      <td>293</td>\n      <td>0.840100</td>\n    </tr>\n    <tr>\n      <td>294</td>\n      <td>0.934800</td>\n    </tr>\n    <tr>\n      <td>295</td>\n      <td>0.744800</td>\n    </tr>\n    <tr>\n      <td>296</td>\n      <td>0.744100</td>\n    </tr>\n    <tr>\n      <td>297</td>\n      <td>0.806100</td>\n    </tr>\n    <tr>\n      <td>298</td>\n      <td>0.916200</td>\n    </tr>\n    <tr>\n      <td>299</td>\n      <td>0.943800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.828600</td>\n    </tr>\n    <tr>\n      <td>301</td>\n      <td>0.827400</td>\n    </tr>\n    <tr>\n      <td>302</td>\n      <td>0.758600</td>\n    </tr>\n    <tr>\n      <td>303</td>\n      <td>0.902300</td>\n    </tr>\n    <tr>\n      <td>304</td>\n      <td>0.942700</td>\n    </tr>\n    <tr>\n      <td>305</td>\n      <td>0.837900</td>\n    </tr>\n    <tr>\n      <td>306</td>\n      <td>0.763900</td>\n    </tr>\n    <tr>\n      <td>307</td>\n      <td>0.802400</td>\n    </tr>\n    <tr>\n      <td>308</td>\n      <td>0.795400</td>\n    </tr>\n    <tr>\n      <td>309</td>\n      <td>0.787700</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.850500</td>\n    </tr>\n    <tr>\n      <td>311</td>\n      <td>0.815800</td>\n    </tr>\n    <tr>\n      <td>312</td>\n      <td>0.774500</td>\n    </tr>\n    <tr>\n      <td>313</td>\n      <td>0.873500</td>\n    </tr>\n    <tr>\n      <td>314</td>\n      <td>0.796100</td>\n    </tr>\n    <tr>\n      <td>315</td>\n      <td>0.855800</td>\n    </tr>\n    <tr>\n      <td>316</td>\n      <td>0.796100</td>\n    </tr>\n    <tr>\n      <td>317</td>\n      <td>0.752200</td>\n    </tr>\n    <tr>\n      <td>318</td>\n      <td>0.753000</td>\n    </tr>\n    <tr>\n      <td>319</td>\n      <td>0.861900</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.897100</td>\n    </tr>\n    <tr>\n      <td>321</td>\n      <td>0.779200</td>\n    </tr>\n    <tr>\n      <td>322</td>\n      <td>0.793700</td>\n    </tr>\n    <tr>\n      <td>323</td>\n      <td>0.923200</td>\n    </tr>\n    <tr>\n      <td>324</td>\n      <td>0.816400</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.742200</td>\n    </tr>\n    <tr>\n      <td>326</td>\n      <td>0.693000</td>\n    </tr>\n    <tr>\n      <td>327</td>\n      <td>0.851100</td>\n    </tr>\n    <tr>\n      <td>328</td>\n      <td>0.832400</td>\n    </tr>\n    <tr>\n      <td>329</td>\n      <td>0.784000</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.857100</td>\n    </tr>\n    <tr>\n      <td>331</td>\n      <td>0.847100</td>\n    </tr>\n    <tr>\n      <td>332</td>\n      <td>0.804200</td>\n    </tr>\n    <tr>\n      <td>333</td>\n      <td>0.874900</td>\n    </tr>\n    <tr>\n      <td>334</td>\n      <td>0.943600</td>\n    </tr>\n    <tr>\n      <td>335</td>\n      <td>0.875300</td>\n    </tr>\n    <tr>\n      <td>336</td>\n      <td>0.842800</td>\n    </tr>\n    <tr>\n      <td>337</td>\n      <td>0.944000</td>\n    </tr>\n    <tr>\n      <td>338</td>\n      <td>0.792100</td>\n    </tr>\n    <tr>\n      <td>339</td>\n      <td>0.658800</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.877800</td>\n    </tr>\n    <tr>\n      <td>341</td>\n      <td>0.930400</td>\n    </tr>\n    <tr>\n      <td>342</td>\n      <td>0.745700</td>\n    </tr>\n    <tr>\n      <td>343</td>\n      <td>0.805300</td>\n    </tr>\n    <tr>\n      <td>344</td>\n      <td>0.916100</td>\n    </tr>\n    <tr>\n      <td>345</td>\n      <td>0.869700</td>\n    </tr>\n    <tr>\n      <td>346</td>\n      <td>0.841200</td>\n    </tr>\n    <tr>\n      <td>347</td>\n      <td>0.781500</td>\n    </tr>\n    <tr>\n      <td>348</td>\n      <td>0.830300</td>\n    </tr>\n    <tr>\n      <td>349</td>\n      <td>0.736500</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.881500</td>\n    </tr>\n    <tr>\n      <td>351</td>\n      <td>0.733600</td>\n    </tr>\n    <tr>\n      <td>352</td>\n      <td>0.863400</td>\n    </tr>\n    <tr>\n      <td>353</td>\n      <td>0.801300</td>\n    </tr>\n    <tr>\n      <td>354</td>\n      <td>0.899400</td>\n    </tr>\n    <tr>\n      <td>355</td>\n      <td>0.793500</td>\n    </tr>\n    <tr>\n      <td>356</td>\n      <td>0.844800</td>\n    </tr>\n    <tr>\n      <td>357</td>\n      <td>0.813300</td>\n    </tr>\n    <tr>\n      <td>358</td>\n      <td>0.838900</td>\n    </tr>\n    <tr>\n      <td>359</td>\n      <td>0.837300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.917400</td>\n    </tr>\n    <tr>\n      <td>361</td>\n      <td>0.806900</td>\n    </tr>\n    <tr>\n      <td>362</td>\n      <td>0.800800</td>\n    </tr>\n    <tr>\n      <td>363</td>\n      <td>0.829300</td>\n    </tr>\n    <tr>\n      <td>364</td>\n      <td>0.906600</td>\n    </tr>\n    <tr>\n      <td>365</td>\n      <td>0.902700</td>\n    </tr>\n    <tr>\n      <td>366</td>\n      <td>0.793300</td>\n    </tr>\n    <tr>\n      <td>367</td>\n      <td>0.730700</td>\n    </tr>\n    <tr>\n      <td>368</td>\n      <td>0.796100</td>\n    </tr>\n    <tr>\n      <td>369</td>\n      <td>0.860400</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.843300</td>\n    </tr>\n    <tr>\n      <td>371</td>\n      <td>0.817500</td>\n    </tr>\n    <tr>\n      <td>372</td>\n      <td>0.858100</td>\n    </tr>\n    <tr>\n      <td>373</td>\n      <td>0.707500</td>\n    </tr>\n    <tr>\n      <td>374</td>\n      <td>0.850100</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.737600</td>\n    </tr>\n    <tr>\n      <td>376</td>\n      <td>0.838600</td>\n    </tr>\n    <tr>\n      <td>377</td>\n      <td>0.934000</td>\n    </tr>\n    <tr>\n      <td>378</td>\n      <td>0.844100</td>\n    </tr>\n    <tr>\n      <td>379</td>\n      <td>0.892000</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.818600</td>\n    </tr>\n    <tr>\n      <td>381</td>\n      <td>0.990800</td>\n    </tr>\n    <tr>\n      <td>382</td>\n      <td>0.803400</td>\n    </tr>\n    <tr>\n      <td>383</td>\n      <td>0.819400</td>\n    </tr>\n    <tr>\n      <td>384</td>\n      <td>0.827800</td>\n    </tr>\n    <tr>\n      <td>385</td>\n      <td>0.885200</td>\n    </tr>\n    <tr>\n      <td>386</td>\n      <td>0.898800</td>\n    </tr>\n    <tr>\n      <td>387</td>\n      <td>0.823400</td>\n    </tr>\n    <tr>\n      <td>388</td>\n      <td>0.940500</td>\n    </tr>\n    <tr>\n      <td>389</td>\n      <td>0.782600</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.892800</td>\n    </tr>\n    <tr>\n      <td>391</td>\n      <td>0.741700</td>\n    </tr>\n    <tr>\n      <td>392</td>\n      <td>0.869500</td>\n    </tr>\n    <tr>\n      <td>393</td>\n      <td>0.932800</td>\n    </tr>\n    <tr>\n      <td>394</td>\n      <td>0.715100</td>\n    </tr>\n    <tr>\n      <td>395</td>\n      <td>0.798500</td>\n    </tr>\n    <tr>\n      <td>396</td>\n      <td>0.733000</td>\n    </tr>\n    <tr>\n      <td>397</td>\n      <td>0.784600</td>\n    </tr>\n    <tr>\n      <td>398</td>\n      <td>0.882800</td>\n    </tr>\n    <tr>\n      <td>399</td>\n      <td>0.820100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.855400</td>\n    </tr>\n    <tr>\n      <td>401</td>\n      <td>0.867400</td>\n    </tr>\n    <tr>\n      <td>402</td>\n      <td>0.796000</td>\n    </tr>\n    <tr>\n      <td>403</td>\n      <td>0.762100</td>\n    </tr>\n    <tr>\n      <td>404</td>\n      <td>0.841000</td>\n    </tr>\n    <tr>\n      <td>405</td>\n      <td>0.880900</td>\n    </tr>\n    <tr>\n      <td>406</td>\n      <td>0.746700</td>\n    </tr>\n    <tr>\n      <td>407</td>\n      <td>0.740000</td>\n    </tr>\n    <tr>\n      <td>408</td>\n      <td>0.790200</td>\n    </tr>\n    <tr>\n      <td>409</td>\n      <td>0.860200</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.829500</td>\n    </tr>\n    <tr>\n      <td>411</td>\n      <td>0.768900</td>\n    </tr>\n    <tr>\n      <td>412</td>\n      <td>0.896300</td>\n    </tr>\n    <tr>\n      <td>413</td>\n      <td>0.728500</td>\n    </tr>\n    <tr>\n      <td>414</td>\n      <td>0.930300</td>\n    </tr>\n    <tr>\n      <td>415</td>\n      <td>0.897200</td>\n    </tr>\n    <tr>\n      <td>416</td>\n      <td>0.805000</td>\n    </tr>\n    <tr>\n      <td>417</td>\n      <td>0.926800</td>\n    </tr>\n    <tr>\n      <td>418</td>\n      <td>0.739500</td>\n    </tr>\n    <tr>\n      <td>419</td>\n      <td>0.870000</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.692900</td>\n    </tr>\n    <tr>\n      <td>421</td>\n      <td>0.905700</td>\n    </tr>\n    <tr>\n      <td>422</td>\n      <td>0.905500</td>\n    </tr>\n    <tr>\n      <td>423</td>\n      <td>0.925100</td>\n    </tr>\n    <tr>\n      <td>424</td>\n      <td>0.849600</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.828500</td>\n    </tr>\n    <tr>\n      <td>426</td>\n      <td>0.927700</td>\n    </tr>\n    <tr>\n      <td>427</td>\n      <td>0.782800</td>\n    </tr>\n    <tr>\n      <td>428</td>\n      <td>0.978300</td>\n    </tr>\n    <tr>\n      <td>429</td>\n      <td>0.882400</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.811100</td>\n    </tr>\n    <tr>\n      <td>431</td>\n      <td>0.831300</td>\n    </tr>\n    <tr>\n      <td>432</td>\n      <td>0.691100</td>\n    </tr>\n    <tr>\n      <td>433</td>\n      <td>0.795700</td>\n    </tr>\n    <tr>\n      <td>434</td>\n      <td>0.830000</td>\n    </tr>\n    <tr>\n      <td>435</td>\n      <td>0.815400</td>\n    </tr>\n    <tr>\n      <td>436</td>\n      <td>0.821000</td>\n    </tr>\n    <tr>\n      <td>437</td>\n      <td>0.758600</td>\n    </tr>\n    <tr>\n      <td>438</td>\n      <td>0.743200</td>\n    </tr>\n    <tr>\n      <td>439</td>\n      <td>0.802400</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.858300</td>\n    </tr>\n    <tr>\n      <td>441</td>\n      <td>0.859300</td>\n    </tr>\n    <tr>\n      <td>442</td>\n      <td>0.939100</td>\n    </tr>\n    <tr>\n      <td>443</td>\n      <td>0.854400</td>\n    </tr>\n    <tr>\n      <td>444</td>\n      <td>0.858200</td>\n    </tr>\n    <tr>\n      <td>445</td>\n      <td>0.790400</td>\n    </tr>\n    <tr>\n      <td>446</td>\n      <td>0.730900</td>\n    </tr>\n    <tr>\n      <td>447</td>\n      <td>0.880000</td>\n    </tr>\n    <tr>\n      <td>448</td>\n      <td>0.751600</td>\n    </tr>\n    <tr>\n      <td>449</td>\n      <td>0.795100</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.755800</td>\n    </tr>\n    <tr>\n      <td>451</td>\n      <td>0.815800</td>\n    </tr>\n    <tr>\n      <td>452</td>\n      <td>0.830000</td>\n    </tr>\n    <tr>\n      <td>453</td>\n      <td>0.812200</td>\n    </tr>\n    <tr>\n      <td>454</td>\n      <td>0.774800</td>\n    </tr>\n    <tr>\n      <td>455</td>\n      <td>0.800200</td>\n    </tr>\n    <tr>\n      <td>456</td>\n      <td>0.841800</td>\n    </tr>\n    <tr>\n      <td>457</td>\n      <td>0.675200</td>\n    </tr>\n    <tr>\n      <td>458</td>\n      <td>0.893900</td>\n    </tr>\n    <tr>\n      <td>459</td>\n      <td>0.942800</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.787900</td>\n    </tr>\n    <tr>\n      <td>461</td>\n      <td>0.758100</td>\n    </tr>\n    <tr>\n      <td>462</td>\n      <td>0.718600</td>\n    </tr>\n    <tr>\n      <td>463</td>\n      <td>0.819200</td>\n    </tr>\n    <tr>\n      <td>464</td>\n      <td>0.990500</td>\n    </tr>\n    <tr>\n      <td>465</td>\n      <td>0.823000</td>\n    </tr>\n    <tr>\n      <td>466</td>\n      <td>0.934800</td>\n    </tr>\n    <tr>\n      <td>467</td>\n      <td>0.699600</td>\n    </tr>\n    <tr>\n      <td>468</td>\n      <td>0.795500</td>\n    </tr>\n    <tr>\n      <td>469</td>\n      <td>0.827800</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.758500</td>\n    </tr>\n    <tr>\n      <td>471</td>\n      <td>0.805600</td>\n    </tr>\n    <tr>\n      <td>472</td>\n      <td>0.786200</td>\n    </tr>\n    <tr>\n      <td>473</td>\n      <td>0.827800</td>\n    </tr>\n    <tr>\n      <td>474</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>0.908300</td>\n    </tr>\n    <tr>\n      <td>476</td>\n      <td>0.914700</td>\n    </tr>\n    <tr>\n      <td>477</td>\n      <td>0.719800</td>\n    </tr>\n    <tr>\n      <td>478</td>\n      <td>0.732000</td>\n    </tr>\n    <tr>\n      <td>479</td>\n      <td>0.955100</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.865900</td>\n    </tr>\n    <tr>\n      <td>481</td>\n      <td>0.776500</td>\n    </tr>\n    <tr>\n      <td>482</td>\n      <td>0.787000</td>\n    </tr>\n    <tr>\n      <td>483</td>\n      <td>0.847300</td>\n    </tr>\n    <tr>\n      <td>484</td>\n      <td>0.765300</td>\n    </tr>\n    <tr>\n      <td>485</td>\n      <td>0.854200</td>\n    </tr>\n    <tr>\n      <td>486</td>\n      <td>0.791500</td>\n    </tr>\n    <tr>\n      <td>487</td>\n      <td>0.864700</td>\n    </tr>\n    <tr>\n      <td>488</td>\n      <td>0.776700</td>\n    </tr>\n    <tr>\n      <td>489</td>\n      <td>0.882200</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.886000</td>\n    </tr>\n    <tr>\n      <td>491</td>\n      <td>0.838800</td>\n    </tr>\n    <tr>\n      <td>492</td>\n      <td>0.740300</td>\n    </tr>\n    <tr>\n      <td>493</td>\n      <td>0.690700</td>\n    </tr>\n    <tr>\n      <td>494</td>\n      <td>0.762500</td>\n    </tr>\n    <tr>\n      <td>495</td>\n      <td>0.757800</td>\n    </tr>\n    <tr>\n      <td>496</td>\n      <td>0.781400</td>\n    </tr>\n    <tr>\n      <td>497</td>\n      <td>0.734700</td>\n    </tr>\n    <tr>\n      <td>498</td>\n      <td>0.826000</td>\n    </tr>\n    <tr>\n      <td>499</td>\n      <td>0.813700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.798400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"_uuid":"d713c9cc-4d35-4e48-ae9c-8c1f4129ffc2","_cell_guid":"1e26248c-aca3-452a-b1f2-8880af847169","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T19:59:53.253708Z","iopub.execute_input":"2025-01-25T19:59:53.254055Z","iopub.status.idle":"2025-01-25T19:59:53.262287Z","shell.execute_reply.started":"2025-01-25T19:59:53.254030Z","shell.execute_reply":"2025-01-25T19:59:53.261225Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"3400.8226 seconds used for training.\n56.68 minutes used for training.\nPeak reserved memory = 3.068 GB.\nPeak reserved memory for training = 0.0 GB.\nPeak reserved memory % of max memory = 20.813 %.\nPeak reserved memory for training % of max memory = 0.0 %.\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"from transformers import TextStreamer\n\n# Enable the model for inference\nmodel = FastVisionModel.for_inference(model)\n\n# Load the image as a PIL image\nimage = converted_dataset[2120]['messages'][0]['content'][1]['image']\n\nprint(image)\n\n# Prepare instruction and messages\ninstruction = \"Which dance is begin performed?\"\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": image},  # Pass the resized PIL image directly\n            {\"type\": \"text\", \"text\": instruction}\n        ]\n    }\n]\ninput_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\nprint(input_text)\n\ninputs = tokenizer(\n    image,\n    input_text,\n    add_special_tokens = False,\n    return_tensors = \"pt\",\n).to(\"cuda\")\nprint(inputs)\n\n# Define the text streamer\ntext_streamer = TextStreamer(\n    tokenizer=tokenizer,\n    skip_prompt=True  # Skip showing the input prompt in the output\n)\nprint(text_streamer)\nwith torch.no_grad():  # Disable gradient computation during inference\n    _ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128,\n                       use_cache=True, temperature=1.5, min_p=0.1)","metadata":{"_uuid":"8a980825-4ca7-48e6-ba7e-078d57e19e64","_cell_guid":"8e943bb5-3e56-478c-9ae9-dc3bde5435ac","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T19:59:55.963003Z","iopub.execute_input":"2025-01-25T19:59:55.963340Z","iopub.status.idle":"2025-01-25T20:00:01.839452Z","shell.execute_reply.started":"2025-01-25T19:59:55.963310Z","shell.execute_reply":"2025-01-25T20:00:01.838816Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"<PIL.Image.Image image mode=RGB size=224x224 at 0x7C9B509EB070>\n<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<|vision_start|><|image_pad|><|vision_end|>Which dance is begin performed?<|im_end|>\n<|im_start|>assistant\n\n{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151655, 151655, 151655,\n         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655,\n         151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653,  23085,\n          15254,    374,   3161,  10660,     30, 151645,    198, 151644,  77091,\n            198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n       device='cuda:0'), 'pixel_values': tensor([[-1.5879, -1.5587, -1.5733,  ..., -1.2100, -1.1816, -1.1674],\n        [-1.5587, -1.5149, -1.5003,  ..., -0.9683, -0.9399, -0.8688],\n        [-1.3835, -1.3543, -1.0769,  ..., -1.3380, -1.3380, -1.3238],\n        ...,\n        [-1.4711, -1.4565, -1.4565,  ..., -1.4518, -0.5844,  0.6386],\n        [ 0.0471,  0.0325,  0.0617,  ..., -1.4660, -1.4660, -1.4376],\n        [-0.1426, -0.2740, -0.4638,  ..., -1.4518, -1.4376, -1.4376]],\n       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 16, 16]], device='cuda:0')}\n<transformers.generation.streamers.TextStreamer object at 0x7c9ab4717430>\nThe dance that begins is likely the Bhairab Dance, characterized by its elaborate costumes and dramatic performances, which are integral parts of the Bhairab Jatra festival honoring Bhairav, a fierce aspect of Lord Shiva.<|im_end|>\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"model.save_pretrained(\"kaggle/working/qwen2b\")\ntokenizer.save_pretrained(\"kaggle/working/qwen2b\")","metadata":{"_uuid":"7ab3fdc8-c511-4ce8-884f-9d1c431ed932","_cell_guid":"46f61039-f4e1-4357-b58a-8176a2643758","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-25T20:01:51.970158Z","iopub.execute_input":"2025-01-25T20:01:51.970459Z","iopub.status.idle":"2025-01-25T20:01:53.168295Z","shell.execute_reply.started":"2025-01-25T20:01:51.970436Z","shell.execute_reply":"2025-01-25T20:01:53.167503Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"import os \nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T20:05:29.738758Z","iopub.execute_input":"2025-01-25T20:05:29.739106Z","iopub.status.idle":"2025-01-25T20:05:29.743113Z","shell.execute_reply.started":"2025-01-25T20:05:29.739080Z","shell.execute_reply":"2025-01-25T20:05:29.742181Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"# Zip the directory\nshutil.make_archive(\"kaggle/working/qwen2b\", 'zip', \"kaggle/working/qwen2b\")\n\n# Optionally, you can remove the original directory to save space\nshutil.rmtree(\"kaggle/working/qwen2b\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T20:05:31.497737Z","iopub.execute_input":"2025-01-25T20:05:31.498061Z","iopub.status.idle":"2025-01-25T20:05:37.912864Z","shell.execute_reply.started":"2025-01-25T20:05:31.498034Z","shell.execute_reply":"2025-01-25T20:05:37.911519Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}